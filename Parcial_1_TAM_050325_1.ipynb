{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObfiDcAB3E9tKG5+6O1YGt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pedro-Ortega-G/PARCIAL_1_TAM_GH/blob/main/Parcial_1_TAM_050325_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREGUNTAS\n",
        "\n",
        "2.1. (Valor 2.5 puntos). Sea el modelo de regresi´on tn = ?(xn)w? + ?n, con {tn ? R, xn ? RP }Nn\n",
        "=1, w ? RQ, ? : RP ? RQ, Q = P, y ?n ~ N(?n|0, s2 ?). Presente el problema de optimizaci´on (inferencia) y la soluci´on del mismo para los modelos\n",
        "m´inimos cuadrados, m´inimos cuadrados regularizados, m´axima verosilimitud, m´aximo a-posteriori, Bayesiano con modelo lineal\n",
        "Gaussiano, regresi´on r´igida kernel y mediante procesos Gaussianos. Asuma datos i.i.d. Discuta las diferencias y similitudes entre\n",
        "los modelos estudiados.\n",
        "\n",
        "R/ el archivo \"PUNTO1.doc\" (https://github.com/Pedro-Ortega-G/PARCIAL_1_TAM/releases/download/A1/PUNTO1.docx) contiene el desarrollo de este punto.\n",
        "\n",
        "\n",
        "2.2 (Valor 2.5 puntos) Utilizando un esquema de validación cruzada de 5 folds, compare el rendimiento de los siguientes regresores\n",
        "sobre el conjunto de datos NBA scored prediction de Kaggle:\n",
        "• LinearRegresor\n",
        "• Lasso\n",
        "• ElasticNet\n",
        "• KernelRidge\n",
        "• SGDRegressor\n",
        "• BayesianRidge\n",
        "• Gaussian Process Regressor\n",
        "• RandomForestRegressor\n",
        "• Support Vector Machines Regressor\n",
        "fijando el score del gridsearch en t´erminos del error absoluto medio y el error cu´adratico medio (MAE y MSE). Justifique los\n",
        "hiperpar´ametros a buscar y la rejilla de valores escogida para cada algoritmo seg´un los modelos estudiados en clase. Finalmente,\n",
        "presente los rendimientos promedios en los datos de evaluaci´on con su respectiva desviaci´on est´andar para las siguientes medidas\n",
        "de desempe˜no: MAE, MSE, R2 (consultar) y MAPE (consultar).\n",
        "\n",
        "\n",
        "R/\n",
        "\n",
        "Observaciones:\n",
        "1. Inicialmente se descarga la base de datos \"2023_nba_player_stats.csv\" (https://github.com/Pedro-Ortega-G/PARCIAL_1_TAM/releases/download/A1/2023_nba_player_stats.csv) siguiendo el link indicado en la guia.\n",
        "\n",
        "2. Se carga la base de datos directamente desde mi github\n",
        "\n",
        "DESARROLLO:\n",
        "-\tSe configura el parámetro \"Min\" (minutos de juego por temporada) como objetivo del regresor y se usan los otros parámetros como entradas\n",
        "del regresor.\n",
        "\n",
        "-\tInicialmente se realiza un entrenamiento (el archivo anexo \"regresiones_varias_gh.ipynb\", https://github.com/Pedro-Ortega-G/PARCIAL_1_TAM_GH/blob/main/regresiones_varias_gh.ipynb , muestra este proceso y sus resultados) tipo hold-out\n",
        "(aplicando los hiperparámetros configurados por default) sobre el set completo de datos (538 elementos) aplicando todos los regresores de la lista;\n",
        "los resusltados muestran que un primer grupo de regresores (Linear, Lasso, ElasticNet, BayesianRidge y RandomForestRegressor ) presenta resultados\n",
        "satisfactorios (con MAE del orden de 113) y otro grupo (KernelRidge, SGDRegressor, GaussianProcessRegressor y SupportVectorMachinesRegressor)\n",
        "no converge (con MAE del orden de 1000).\n",
        "\n",
        "-\tLuego se aplica el método \"GridSearchCV\" para encontrar los mejores hiperparámetros para los regresores que no convergen (KernelRidge y\n",
        "SGDRegressor) con los hiperparámetros configurados por default.\n",
        "-\tLuego se configura kernel de tipo \"DotProduct() + WhiteKernel()\" en el GaussianProcessRegressor y tipo \"linear\" en el Support Vector Machines\n",
        "Regressor. Esto se configura manualmente a partir del criterio visual que indica la linealidad de los datos.\n",
        "\n",
        "-\tEl archivo \"regresiones_varias_hiperparametros_4_ok_gh.ipynb\" (https://github.com/Pedro-Ortega-G/PARCIAL_1_TAM_GH/blob/main/regresiones_varias_hiperparametros_4_ok_gh.ipynb) muestra los resultados obtenidos. Todos los regresores convergen con MAE del\n",
        "orden de 120.\n",
        "\n",
        "-\tLuego se aplica el esquema de validación cruzada (el archivo anexo \"regresiones_5folds_5_ok_gh.ipynb\" (https://github.com/Pedro-Ortega-G/PARCIAL_1_TAM_GH/blob/main/regresiones_5folds_5_ok_gh.ipynb)expone los resultados) y se compara\n",
        "el rendimiento promedio obteniendo los siguientes resultados (el archivo \"Métricas en datos de prueba para todos los modelos.doc\" contiene los\n",
        "valores numéricos de las métricas evaluadas):\n",
        "\t1. De acuerdo a la evaluación de las métricas obtenidas, el regresor tipo \"LinearRegresion\" mostró los peores resultados\n",
        "\t2. De acuerdo a la evaluación de la métrica MAE y MSE, el regresor tipo \"SVM\" mostró los mejores resultados\n",
        "\t3. De acuerdo a la evaluación de la métrica R2 y MAPE, el regresor tipo \"SGDRegressor\" mostró los mejores resultados\n",
        "\n",
        "     "
      ],
      "metadata": {
        "id": "4f09E8f7GdFx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hREqddvGERs"
      },
      "outputs": [],
      "source": []
    }
  ]
}